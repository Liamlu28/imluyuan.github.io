---
layout:     post
title:      "Haproxy服务的概述与原理介绍"
subtitle:   "Haproxy服务"
date:       2017-02-18 00:00:00
author:     "Luyuan"
header-img: "img/web/haprxoy.jpg"
catalog: true
tags:
    - Web
---


#1 前言
Web服务遍及我们生活各处角落，咱们使用天猫、京东、手机APP等等遍历与我们生活的各个角落，比如我们在访问网页时它的工作流程是什么，使用到什么技术，今天我们就来
聊一些Haproxy这个组件。

##2.1 Haproxy的简介
Haproxy是高可用代理软件，它是一种比较流行的开源软件，基于TCP(四层)/HTTP(七层)协议的负载均衡代理解决方案，可以在Linux、FreeBSD等平台下运行，常见于跨多个服务器，比如:web、应用程序、数据库、MQ消息队列、MC数据库等等。通过多个Haproxy服务来提高服务的性能和可靠性。常见的使用案列：openstack社区，GITHUB等一些网站。
##2.2 Haproxy的works
haproxy是一个单线程，事件驱动，给予优先级调度非阻塞已经集合快速I/O的程序，它涉及理念源自于数据转发，它是一个优良架构，可以快速移动数据并减少数据的操作时间。因此它实现了分层模式，在每个级别提供旁路机制，从而确保数据不会去往更高层。Haproxy大多数情况下实在内核中完成处理的，当haproxy认为这些数据可以数组后，会尽力帮助内核尽快完成工作，并给出一个提示或者它会避免某些操作。haproxy单个进程可以运行很多实例，他可以运行接近30W个不同的代理，所以不需要为每个实例都开启多个进程。

当haproxy启动后，它只做三件事情：
0.客户端发送请求-> 1.Haproxy开始处理传入的链接 -> 2.定期检查服务后端服务的状态 ->3.与其它haproxy节点交换信息

##2.3 处理传入的链接的流程
1.接受来自于a实例前端（frontend）实体链接，实体链接引用了一个或者多个的监听地址。
2.ACL规则来判断这些链接是否被拦截，规则可以修改这些链接标题或拦截他们执行内部小程序，比如：页面统计
3.过滤规则完成后，将这些链接传递给后端实体（backend）,后端服务器中包含负载均衡的策略（比如：roundrobin策略）
4.将后端特定的处理规则应用于这些连接
5.根据负载均衡的策略来转发链接给backend
6.将后端特定的处理规则应用于响应数据
7.将前端特定的处理规则应用于响应数据
8.返回一个日志来报告发生的细节
9.在HTTP中，循环回到第二步，等待新的请求，否则关闭连接

前端和后端有时被认为是半代理，因为它们只有看一端端对端的连接;前端只关心客户端，而后端只关心服务器。 HAProxy也支持完全代理，正是前端和后端的联合。当HTTP
期望处理，该配置通常将被分割成前端和后端，因为他们开启了很多可能性，因为任何一个前端都可能通过连接到任何后端。使用仅TCP代理，使用前端和后端很少提供一个好处，配置可以更完整地阅读代理人.

##3 haprxy术语
讲完Haporxy的工作原理后，我们继续讲解Haproxy的一些术语，术语和概览理解是非常重要的。
##3.1 访问控制列表（ACL）
ACL从字面理解访问控制列表，在Haproxy当中它的定制法则很简单：开放策略：拒绝所有，只开放已知。拒绝策略：允许所有，只拒绝某些。通过ACL可以过滤部分关键字，可以保证服务器安全性。
##3.2 前端
前端定义请求如何转发到后端。前端在HAProxy配置的前端部分定义。它们的定义由以下组件组成：
*一组IP地址和端口（例如10.1.1.7:80，*：443等）
*ACL
*use_backend规则，它们根据哪个ACL条件进行匹配来定义要使用的后端，和/或处理每个其他情况的default_backend规则
##3.3 后端
后端是一组接收转发请求的服务器。后端在HAProxy配置的后端部分定义。在其最基本的形式中，后端可以通过以下方式定义：
*哪种负载均衡算法使用
*服务器和端口列表
后端可以包含一个或多个服务器 - 通常来说，向后端添加更多服务器将通过将负载分散在多个服务器上来增加潜在的负载能力。通过这种方式也可以提高可靠性，以防某些后台服务器变得不可用。

##4 负载平衡类型
###4.1 无负载平衡
![1](/img/web/web_server.png)
在此示例中，用户直接连接到您的Web服务器，位于yourdomain.com，没有任何负载平衡。如果您的单个Web服务器关闭，用户将无法再访问您的Web服务器。另外，如果许多用户尝试同时访问您的服务器，并且无法处理该负载，那么它们的体验速度可能较慢，或者根本无法连接。
###4.2 第4层负载平衡
![2](/img/web/layer_4_load_balancing.png)
将网络流量负载平衡到多个服务器的最简单的方法是使用第4层（传输层）负载平衡。负载平衡这种方式基于IP范围和端口（即会转发用户流量，如果一个请求进入http://yourdomain.com/anything，流量将被转发到处理所有的请求后端yourdomain.com上港口80）。对于第4层的详细信息，请查看TCP我们的小节介绍网络。
用户访问负载平衡器，负载平衡器将用户的请求转发到后端服务器的后端组。选择哪个后端服务器将直接响应用户的请求。通常，Web后端中的所有服务器都应该服务相同的内容 - 否则用户可能会收到不一致的内容。请注意，两个Web服务器都连接到同一个数据库服务器。
###4.3 第7层负载平衡
![3](/img/web/layer_7_load_balancing.png)
负载平衡网络流量的另一种更复杂的方法是使用第7层（应用层）负载平衡。使用第7层允许负载均衡器根据用户请求的内容将请求转发到不同的后端服务器。这种负载平衡模式允许您在相同的域和端口下运行多个Web应用程序服务器.
在此示例中，如果用户请求yourdomain.com/blog，则将其转发到博客后端，该后端是运行博客应用程序的一组服务器。其他请求被转发到可能运行另一个应用程序的Web后端。在这个例子中，两个后端都使用相同的数据库服务器。
##5 负载平衡算法
使用的负载平衡算法决定了在负载平衡时将在后台选择哪个服务器。HAProxy为算法提供了几个选项。除负载平衡算法外，与其他服务器相比，服务器可以分配一个权重参数来操纵服务器选择频率。
一些常用的算法如下：

###6.1 roundrobin算法
Round Robin轮询选择服务器。这是默认算法。

###6.2 leastconn算法
连接数最少的服务器优先接收连接。

###6.3 source算法
对请求源IP地址进行哈希，用可用服务器的权重总数除以哈希值，根据结果进行分配。

##7 健康检查
Haproxy使用健康检查来确定后端服务器是否可用于处理请求。 这样可以避免在服务器不可用时从后端手动删除服务器。 默认运行状况检查是尝试建立到服务器的TCP连接，即它检查后端服务器是否在配置的IP地址和端口上侦听。

##8 总结
我们介绍了Haproxy的基本概念，术语，还有它的工作原理如何处理客户端请求的链接，同时也讲解了4与7层，最后讲解了负载均衡的平衡算法。后面会重点介绍它的负载平衡算法的源码解析。

##9 参考
https://cbonte.github.io/haproxy-dconv/1.7/intro.html#3.2


—— Luyuan 后记于 2017.02.17
